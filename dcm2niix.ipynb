{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOkiIK8Ph80VxTmZSJ5ilp9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e4035d385f94b5e9f4dd8cec28dc443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf2ad61b23f843ad84078f1515e91c77",
              "IPY_MODEL_b57cdc6b3ff84578b0118b194a9437f2",
              "IPY_MODEL_f65e300c992f4d7b8cdbf7a8bdf6ba31"
            ],
            "layout": "IPY_MODEL_55e0fefcb9814301a405680308081381"
          }
        },
        "bf2ad61b23f843ad84078f1515e91c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3752f39d2c284e16b1ec51f04004ae86",
            "placeholder": "​",
            "style": "IPY_MODEL_6e947b2fe8ea46c8b47d5cecec817a5d",
            "value": "100%"
          }
        },
        "b57cdc6b3ff84578b0118b194a9437f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7337612d4ac141d5b5b9b16bb501e899",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51b1d79488c446c28de08315d5547e46",
            "value": 5
          }
        },
        "f65e300c992f4d7b8cdbf7a8bdf6ba31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afa4d3121913481b8688523b81277676",
            "placeholder": "​",
            "style": "IPY_MODEL_bb9e9f514c4b4fe6993e9fcb3ca47f02",
            "value": " 5/5 [00:04&lt;00:00,  1.56it/s]"
          }
        },
        "55e0fefcb9814301a405680308081381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3752f39d2c284e16b1ec51f04004ae86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e947b2fe8ea46c8b47d5cecec817a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7337612d4ac141d5b5b9b16bb501e899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b1d79488c446c28de08315d5547e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afa4d3121913481b8688523b81277676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9e9f514c4b4fe6993e9fcb3ca47f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariprati/notebooks/blob/main/prova2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7ylAcQngRLkf",
        "outputId": "c1ad9544-94d2-4364-948c-0387b0e57e39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dicom2nifti\n",
            "  Downloading dicom2nifti-2.5.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (5.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (1.13.1)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti)\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting python-gdcm (from dicom2nifti)\n",
            "  Downloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel->dicom2nifti) (6.4.5)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel->dicom2nifti) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel->dicom2nifti) (4.12.2)\n",
            "Downloading dicom2nifti-2.5.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-gdcm, pydicom, dicom2nifti\n",
            "Successfully installed dicom2nifti-2.5.0 pydicom-3.0.1 python-gdcm-3.0.24.1\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (5.3.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel) (6.4.5)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel) (4.12.2)\n",
            "Collecting totalsegmentator\n",
            "  Downloading TotalSegmentator-2.4.0-py3-none-any.whl.metadata (972 bytes)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from totalsegmentator) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from totalsegmentator) (1.26.4)\n",
            "Collecting SimpleITK (from totalsegmentator)\n",
            "  Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: nibabel>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from totalsegmentator) (5.3.2)\n",
            "Requirement already satisfied: tqdm>=4.45.0 in /usr/local/lib/python3.10/dist-packages (from totalsegmentator) (4.66.6)\n",
            "Collecting p-tqdm (from totalsegmentator)\n",
            "  Downloading p_tqdm-1.4.2.tar.gz (6.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xvfbwrapper (from totalsegmentator)\n",
            "  Downloading xvfbwrapper-0.2.9.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nnunetv2>=2.2.1 (from totalsegmentator)\n",
            "  Downloading nnunetv2-2.5.1.tar.gz (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.0/197.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rt-utils (from totalsegmentator)\n",
            "  Downloading rt_utils-1.2.7-py2.py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: dicom2nifti in /usr/local/lib/python3.10/dist-packages (from totalsegmentator) (2.5.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from totalsegmentator) (17.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from totalsegmentator) (2.32.3)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel>=2.3.0->totalsegmentator) (6.4.5)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel>=2.3.0->totalsegmentator) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel>=2.3.0->totalsegmentator) (4.12.2)\n",
            "Collecting acvl-utils<0.3,>=0.2 (from nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading acvl_utils-0.2.2.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dynamic-network-architectures<0.4,>=0.3.1 (from nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnunetv2>=2.2.1->totalsegmentator) (1.13.1)\n",
            "Collecting batchgenerators>=0.25 (from nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nnunetv2>=2.2.1->totalsegmentator) (1.5.2)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from nnunetv2>=2.2.1->totalsegmentator) (0.24.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nnunetv2>=2.2.1->totalsegmentator) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from nnunetv2>=2.2.1->totalsegmentator) (0.20.3)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from nnunetv2>=2.2.1->totalsegmentator) (2024.9.20)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nnunetv2>=2.2.1->totalsegmentator) (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from nnunetv2>=2.2.1->totalsegmentator) (0.13.2)\n",
            "Collecting imagecodecs (from nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading imagecodecs-2024.9.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting yacs (from nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting batchgeneratorsv2>=0.2 (from nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading batchgeneratorsv2-0.2.1.tar.gz (34 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from nnunetv2>=2.2.1->totalsegmentator) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->totalsegmentator) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->totalsegmentator) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->totalsegmentator) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->totalsegmentator) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->totalsegmentator) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->totalsegmentator) (1.3.0)\n",
            "Requirement already satisfied: pydicom>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from dicom2nifti->totalsegmentator) (3.0.1)\n",
            "Requirement already satisfied: python-gdcm in /usr/local/lib/python3.10/dist-packages (from dicom2nifti->totalsegmentator) (3.0.24.1)\n",
            "Collecting pathos>=0.2.5 (from p-tqdm->totalsegmentator)\n",
            "  Downloading pathos-0.3.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from p-tqdm->totalsegmentator) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->totalsegmentator) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->totalsegmentator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->totalsegmentator) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->totalsegmentator) (2024.8.30)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from rt-utils->totalsegmentator) (4.10.0.84)\n",
            "Collecting dataclasses (from rt-utils->totalsegmentator)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting connected-components-3d (from acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading connected_components_3d-3.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Collecting blosc2>=3.0.0b4 (from acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading blosc2-3.0.0b4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2>=2.2.1->totalsegmentator) (11.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2>=2.2.1->totalsegmentator) (1.0.0)\n",
            "Collecting unittest2 (from batchgenerators>=0.25->nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2>=2.2.1->totalsegmentator) (3.5.0)\n",
            "Collecting fft-conv-pytorch (from batchgeneratorsv2>=0.2->nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting ppft>=1.7.6.9 (from pathos>=0.2.5->p-tqdm->totalsegmentator)\n",
            "  Downloading ppft-1.7.6.9-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dill>=0.3.9 (from pathos>=0.2.5->p-tqdm->totalsegmentator)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pox>=0.3.5 (from pathos>=0.2.5->p-tqdm->totalsegmentator)\n",
            "  Downloading pox-0.3.5-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting multiprocess>=0.70.17 (from pathos>=0.2.5->p-tqdm->totalsegmentator)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2>=2.2.1->totalsegmentator) (2.36.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2>=2.2.1->totalsegmentator) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->totalsegmentator) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2>=2.2.1->totalsegmentator) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2>=2.2.1->totalsegmentator) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2>=2.2.1->totalsegmentator) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2>=2.2.1->totalsegmentator) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2>=2.2.1->totalsegmentator) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2>=2.2.1->totalsegmentator) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2>=2.2.1->totalsegmentator) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2>=2.2.1->totalsegmentator) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nnunetv2>=2.2.1->totalsegmentator) (1.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs->nnunetv2>=2.2.1->totalsegmentator) (6.0.2)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.10/dist-packages (from blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator) (1.9.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator) (1.1.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator) (2.10.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator) (9.0.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator) (0.28.0)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25->nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting traceback2 (from unittest2->batchgenerators>=0.25->nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator) (0.14.0)\n",
            "Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2>=2.2.1->totalsegmentator)\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2>=2.2.1->totalsegmentator) (1.2.2)\n",
            "Downloading TotalSegmentator-2.4.0-py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.5/347.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rt_utils-1.2.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading pathos-0.3.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Downloading imagecodecs-2024.9.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading blosc2-3.0.0b4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pox-0.3.5-py3-none-any.whl (29 kB)\n",
            "Downloading ppft-1.7.6.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading connected_components_3d-3.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: nnunetv2, p-tqdm, xvfbwrapper, acvl-utils, batchgenerators, batchgeneratorsv2, dynamic-network-architectures\n",
            "  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.5.1-py3-none-any.whl size=264367 sha256=64512ffaca4475988da66b98da84ac8e97003cc41852a969b68818738fe027dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/d6/90/88743b341922dc9f6795742570aac83a1eaa55f77ee676a5a6\n",
            "  Building wheel for p-tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for p-tqdm: filename=p_tqdm-1.4.2-py3-none-any.whl size=5400 sha256=077fcc19043eb6405aab1ec0abc5af3c89c31d50a4dd01eae9632101e06d2b8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/eb/46/364fe18b96fa8438176535990d8c8ac9ac87becde4cd340d3d\n",
            "  Building wheel for xvfbwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xvfbwrapper: filename=xvfbwrapper-0.2.9-py3-none-any.whl size=5010 sha256=82195c4753fe9219fe5e986b4f3cecdc45a7e15d23293680aff801d5a72e9979\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/10/7d/2b7fdffccf837f7d5425931575fbee9caebe2c190931f9058b\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acvl-utils: filename=acvl_utils-0.2.2-py3-none-any.whl size=24723 sha256=39ebff59bd18ed31638b382fc71bd29e6e987ae361b5f584099e258768bce522\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/56/f0/c3ece6950db0c5fb6ad37b5ce1406a4a1b035840c468c53202\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=ab98ea058eaf09847e6acdb5210904f4f37eb5336085b40769905a3b77754f30\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/1b/30/b3f066999ad01855fc903fe7c93c25682333dd5645d5c75434\n",
            "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.2.1-py3-none-any.whl size=45185 sha256=a07924d0cab12f24d3061b6a18cd03f499e1e6f322429cf5cf7c6220d170ae1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/91/33993997db216e7b946d379850c47837d2478be49377a6cb41\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30046 sha256=19ad32c85fddda0505917e8e14536fa0b12eeffc16695780e692bd16233cdf5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/1b/13/a6419c8dbf998b9343710355ec3edc5c8e24d9b7b22eec95fb\n",
            "Successfully built nnunetv2 p-tqdm xvfbwrapper acvl-utils batchgenerators batchgeneratorsv2 dynamic-network-architectures\n",
            "Installing collected packages: xvfbwrapper, SimpleITK, linecache2, dataclasses, argparse, yacs, traceback2, ppft, pox, imagecodecs, dill, connected-components-3d, unittest2, rt-utils, multiprocess, pathos, fft-conv-pytorch, dynamic-network-architectures, blosc2, batchgenerators, p-tqdm, batchgeneratorsv2, acvl-utils, nnunetv2, totalsegmentator\n",
            "  Attempting uninstall: blosc2\n",
            "    Found existing installation: blosc2 2.7.1\n",
            "    Uninstalling blosc2-2.7.1:\n",
            "      Successfully uninstalled blosc2-2.7.1\n",
            "Successfully installed SimpleITK-2.4.0 acvl-utils-0.2.2 argparse-1.4.0 batchgenerators-0.25.1 batchgeneratorsv2-0.2.1 blosc2-3.0.0b4 connected-components-3d-3.21.0 dataclasses-0.6 dill-0.3.9 dynamic-network-architectures-0.3.1 fft-conv-pytorch-1.2.0 imagecodecs-2024.9.22 linecache2-1.0.0 multiprocess-0.70.17 nnunetv2-2.5.1 p-tqdm-1.4.2 pathos-0.3.3 pox-0.3.5 ppft-1.7.6.9 rt-utils-1.2.7 totalsegmentator-2.4.0 traceback2-1.4.0 unittest2-1.1.0 xvfbwrapper-0.2.9 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "dataclasses"
                ]
              },
              "id": "17c61c8105c042f09c5d115213cc9fa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement shutil (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for shutil\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting dcm2niix\n",
            "  Downloading dcm2niix-1.0.20220715.tar.gz (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.4/451.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting miutil[web] (from dcm2niix)\n",
            "  Downloading miutil-0.12.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.40.0 in /usr/local/lib/python3.10/dist-packages (from miutil[web]->dcm2niix) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from miutil[web]->dcm2niix) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->miutil[web]->dcm2niix) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->miutil[web]->dcm2niix) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->miutil[web]->dcm2niix) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->miutil[web]->dcm2niix) (2024.8.30)\n",
            "Downloading miutil-0.12.0-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: dcm2niix\n",
            "  Building wheel for dcm2niix (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dcm2niix: filename=dcm2niix-1.0.20220715-cp310-cp310-linux_x86_64.whl size=559550 sha256=1b2bb4481aad3632193deacdec96f11ed3a02df803477d215ef69ab98aeadf51\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/8d/9b/5ea20c0451a1acddef585757be7dfec121ee076e58503b267c\n",
            "Successfully built dcm2niix\n",
            "Installing collected packages: miutil, dcm2niix\n",
            "Successfully installed dcm2niix-1.0.20220715 miutil-0.12.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement subprocess (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for subprocess\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install dicom2nifti\n",
        "!pip install nibabel\n",
        "!pip install totalsegmentator\n",
        "!pip install shutil\n",
        "!pip install pydicom\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install dcm2niix\n",
        "! pip install subprocess\n",
        "!pip install os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import dicom2nifti\n",
        "import nibabel as nib\n",
        "from totalsegmentator.python_api import totalsegmentator\n",
        "import shutil\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import dicom2nifti\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import dcm2niix\n",
        "import subprocess\n"
      ],
      "metadata": {
        "id": "xSvhRbV7Rp8T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dicom_folder_to_nifti(dicom_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Converts a directory of DICOM files to a NIfTI volume and saves it using dcm2niix.\n",
        "    \"\"\"\n",
        "    # Ensure the output folder exists\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Define the output filename format\n",
        "    folder_name = os.path.basename(os.path.normpath(dicom_folder))\n",
        "    filename_format = f\"{folder_name}_nifti\"\n",
        "\n",
        "    # Construct the dcm2niix command\n",
        "    command = [\n",
        "        \"dcm2niix\",\n",
        "        \"-z\", \"y\",  # Compress the output using gzip\n",
        "        \"-f\", filename_format,  # Custom filename format\n",
        "        \"-o\", output_folder,  # Output directory\n",
        "        dicom_folder  # Input directory containing DICOM files\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Execute the command\n",
        "        result = subprocess.run(command, check=True, text=True, capture_output=True)\n",
        "        print(\"DICOM to NIfTI conversion successful!\")\n",
        "        print(\"Output:\", result.stdout)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"Error during conversion!\")\n",
        "        print(\"Output:\", e.stderr)\n",
        "\n",
        "\n",
        "\n",
        "def get_nifti_info(nifti_path):\n",
        "    \"\"\"Extracts and prints the dimensions and metadata of a NIfTI file.\"\"\"\n",
        "    # Load the NIfTI image\n",
        "    nifti_img = nib.load(nifti_path)\n",
        "\n",
        "    # Get the data array dimensions\n",
        "    dimensions = nifti_img.shape  # This gives the number of pixels along each axis\n",
        "\n",
        "    # Get the voxel size\n",
        "    voxel_sizes = nifti_img.header.get_zooms()  # Pixel size along each axis in millimeters\n",
        "\n",
        "    # Print the information\n",
        "    print(f\"Dimensions (pixels along each axis): {dimensions}\")\n",
        "    print(f\"Voxel sizes (mm per axis): {voxel_sizes}\")\n",
        "    print(f\"Data type: {nifti_img.get_data_dtype()}\")\n",
        "    print(f\"Affine transformation matrix:\\n{nifti_img.affine}\")\n",
        "\n",
        "    return {\n",
        "        \"dimensions\": dimensions,\n",
        "        \"voxel_sizes\": voxel_sizes,\n",
        "        \"data_type\": nifti_img.get_data_dtype(),\n",
        "        \"affine\": nifti_img.affine\n",
        "    }\n",
        "\n",
        "def find_and_save_slices(dicom_folder, target_value):\n",
        "    \"\"\"\n",
        "    Finds the DICOM slice with a specific InstanceNumber, extracts its\n",
        "    ImagePatientPosition, and returns it as a vector (x, y, z).\n",
        "\n",
        "    Parameters:\n",
        "        dicom_folder (str): Path to the folder containing DICOM files.\n",
        "        target_value (int): The target InstanceNumber to find.\n",
        "\n",
        "    Returns:\n",
        "        tuple: The ImagePatientPosition as a tuple (x, y, z).\n",
        "    \"\"\"\n",
        "    # Load all DICOM files in the folder and sort by Instance Number\n",
        "    dicom_files = sorted(\n",
        "        [f for f in os.listdir(dicom_folder) if f.endswith(\".dcm\")],\n",
        "        key=lambda x: pydicom.dcmread(os.path.join(dicom_folder, x)).InstanceNumber\n",
        "    )\n",
        "\n",
        "    target_index = None\n",
        "    img_patient_position = None\n",
        "\n",
        "    # Iterate over DICOM files to find the slice with InstanceNumber equal to target_value\n",
        "    for i, filename in enumerate(dicom_files):\n",
        "        filepath = os.path.join(dicom_folder, filename)\n",
        "        dicom_data = pydicom.dcmread(filepath)\n",
        "\n",
        "        # Check if the InstanceNumber matches the target value\n",
        "        if dicom_data.InstanceNumber == target_value:\n",
        "            # Extract the ImagePatientPosition of this slice\n",
        "            img_patient_position = dicom_data.ImagePositionPatient  # DICOM tag (0020,0032)\n",
        "            target_index = i\n",
        "            break\n",
        "\n",
        "    # If target slice is not found, exit\n",
        "    if target_index is None:\n",
        "        print(f\"No slice found with InstanceNumber equal to {target_value}\")\n",
        "        return None\n",
        "\n",
        "    # If the slice is found, return the ImagePatientPosition as a tuple\n",
        "    x, y, z = img_patient_position\n",
        "    print(f\"Slice with InstanceNumber {target_value} found at index {target_index}.\")\n",
        "    print(f\"ImagePatientPosition: x={x}, y={y}, z={z}\")\n",
        "    return x, y, z\n",
        "\n",
        "def world_to_voxel_coordinates(header, x, y, z):\n",
        "    \"\"\"\n",
        "    Convert world coordinates (x, y, z) to voxel indices (i, j, k) using the NIfTI header.\n",
        "\n",
        "    Parameters:\n",
        "    header: NIfTI header object (e.g., from nibabel)\n",
        "    x, y, z: World coordinates (float)\n",
        "\n",
        "    Returns:\n",
        "    i, j, k: Voxel indices (int)\n",
        "    \"\"\"\n",
        "    # Extract necessary fields from the header\n",
        "    pixdim = header[\"pixdim\"]\n",
        "    qoffset_x = header[\"qoffset_x\"]\n",
        "    qoffset_y = header[\"qoffset_y\"]\n",
        "    qoffset_z = header[\"qoffset_z\"]\n",
        "    qfac = pixdim[0]  # Either 1 or -1\n",
        "\n",
        "    # Define the fixed rotation matrix R\n",
        "    R = np.array([\n",
        "        [1, 0,  0],\n",
        "        [0, -1, 0],\n",
        "        [0, 0, -1]\n",
        "    ])\n",
        "\n",
        "    # Subtract offsets to account for translation\n",
        "    world_vector = np.array([x, y, z]) - np.array([qoffset_x, qoffset_y, qoffset_z])\n",
        "\n",
        "    # Invert the rotation matrix (which is simple since it's a diagonal matrix)\n",
        "    R_inv = np.linalg.inv(R)\n",
        "\n",
        "    # Apply the inverse rotation\n",
        "    voxel_vector = R_inv @ world_vector\n",
        "\n",
        "    # Divide by the scaling factors to get the voxel indices\n",
        "    i = voxel_vector[0] / pixdim[1]\n",
        "    j = voxel_vector[1] / pixdim[2]\n",
        "    k = voxel_vector[2] / (qfac * pixdim[3])\n",
        "\n",
        "    # Round to the nearest integer to get the voxel indices\n",
        "    i = round(i)\n",
        "    j = round(j)\n",
        "    k = round(k)\n",
        "\n",
        "    return i, j, k\n",
        "\n",
        "def find_sct_slice_number(csv_file, pid, study_yr):\n",
        "    \"\"\"\n",
        "    Finds the sct_slice_number for the given pid and study_yr from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        csv_file (str): Path to the CSV file.\n",
        "        pid (str): Patient ID.\n",
        "        study_yr (str): Study year.\n",
        "\n",
        "    Returns:\n",
        "        int: The corresponding sct_slice_number.\n",
        "    \"\"\"\n",
        "    # Load the CSV file into a DataFrame\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Filter the DataFrame for the specific pid and study_yr\n",
        "    row = df[(df['pid'] == pid) & (df['study_yr'] == study_yr)]\n",
        "\n",
        "    # Check if the row exists and retrieve sct_slice_number\n",
        "    if not row.empty:\n",
        "        print(f\"Matching row from CSV:\\n{row}\\n\")\n",
        "        return int(row['sct_slice_num'].values[0])\n",
        "    else:\n",
        "        raise ValueError(f\"No matching entry found for pid={pid} and study_yr={study_yr}\")\n",
        "\n",
        "\n",
        "def find_sct_epi_loc(csv_file, pid, study_yr):\n",
        "    \"\"\"\n",
        "    Finds the sct_epi_loc for the given pid and study_yr from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        csv_file (str): Path to the CSV file.\n",
        "        pid (str): Patient ID.\n",
        "        study_yr (str): Study year.\n",
        "\n",
        "    Returns:\n",
        "        int: The corresponding sct_epi_loc.\n",
        "    \"\"\"\n",
        "    # Load the CSV file into a DataFrame\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Filter the DataFrame for the specific pid and study_yr\n",
        "    row = df[(df['pid'] == pid) & (df['study_yr'] == study_yr)]\n",
        "\n",
        "    # Check if the row exists and retrieve sct_epi_loc\n",
        "    if not row.empty:\n",
        "        sct_epi_loc = int(row['sct_epi_loc'].values[0])\n",
        "        print(f\"Matching row from CSV:\\n{row}\\n\")\n",
        "        print(f\"sct_epi_loc value: {sct_epi_loc}\")\n",
        "        return sct_epi_loc\n",
        "    else:\n",
        "        raise ValueError(f\"No matching entry found for pid={pid} and study_yr={study_yr}\")\n",
        "\n",
        "\n",
        "def load_lung_lobe_nifti(masked_output_dir, folder_name, sct_epi_loc):\n",
        "    \"\"\"\n",
        "    Loads the NIfTI file corresponding to the lobe based on sct_epi_loc and returns the region name.\n",
        "\n",
        "    Args:\n",
        "        masked_output_dir (str): Directory containing the masked NIfTI files.\n",
        "        folder_name (str): Name of the folder containing the DICOM data.\n",
        "        sct_epi_loc (int): Value determining which lobe to load.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - nib.Nifti1Image: The loaded NIfTI file.\n",
        "            - str: The name of the region (e.g., 'lung_upper_lobe_right').\n",
        "    \"\"\"\n",
        "    nifti_file = None\n",
        "    region = None\n",
        "\n",
        "    # Load the appropriate file based on sct_epi_loc\n",
        "    if sct_epi_loc == 1:\n",
        "        region = 'lung_upper_lobe_right'\n",
        "        nifti_file = nib.load(os.path.join(masked_output_dir, f'{region}.nii.gz'))\n",
        "        print(\"Loaded Right Upper Lobe\")\n",
        "    elif sct_epi_loc == 2:\n",
        "        region = 'lung_middle_lobe_right'\n",
        "        nifti_file = nib.load(os.path.join(masked_output_dir, f'{region}.nii.gz'))\n",
        "        print(\"Loaded Right Middle Lobe\")\n",
        "    elif sct_epi_loc == 3:\n",
        "        region = 'lung_lower_lobe_right'\n",
        "        nifti_file = nib.load(os.path.join(masked_output_dir, f'{region}.nii.gz'))\n",
        "        print(\"Loaded Right Lower Lobe\")\n",
        "    elif sct_epi_loc == 4:\n",
        "        region = 'lung_upper_lobe_left'\n",
        "        nifti_file = nib.load(os.path.join(masked_output_dir, f'{region}.nii.gz'))\n",
        "        print(\"Loaded Left Upper Lobe\")\n",
        "    elif sct_epi_loc in [5, 6]:  # Lingula (5) treated as part of Left Lower Lobe (6)\n",
        "        region = 'lung_lower_lobe_left'\n",
        "        nifti_file = nib.load(os.path.join(masked_output_dir, f'{region}.nii.gz'))\n",
        "        print(\"Loaded Left Lower Lobe (including Lingula)\")\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid sct_epi_loc value: {sct_epi_loc}\")\n",
        "\n",
        "    return nifti_file, region\n"
      ],
      "metadata": {
        "id": "7lPbiQSBSaVd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% MAIN\n",
        "\n",
        "# La funzione *main* è divisa in tre parti:\n",
        "# 1) Creazione del nifti volume a partire dai dicom files + Segmentazione del nifti volume\n",
        "#     1. Carico la cartella contenente tutti i file *.dcm\n",
        "#     2. Trasformazione de dicom a nifti\n",
        "#     3. Definizione delle aree entro cui segmentare i polmoni:\n",
        "#         'lung_upper_lobe_left',\n",
        "#         'lung_lower_lobe_left',\n",
        "#         'lung_upper_lobe_right',\n",
        "#         'lung_middle_lobe_right',\n",
        "#         'lung_lower_lobe_right'\n",
        "#     4. Segmentazione attraverso *TotalSegmentator*\n",
        "# 2) Applicazione maschera alla segmentazione in modo da avere valori discreti dell'immagine originale (+bkgrn messo a valore HU = -1000)\n",
        "# 3) Estrazione del sottovolume (3 slices = 6cm) attorno alla slice centrale in cui il nodulo ha diametro maggiore\n",
        "#     1. Definizione dei dati del paziente: *pid* e *study_yr*\n",
        "#     2. Estrazione delle informazioni dal file *.csv* data la coppia *pid*-*study_yr*\n",
        "#         1. **sci_epi_loc** --> zona dei polmoni in cui si trova la lesione, estrarrò il sottovolume della sua segmentazione\n",
        "#         2. **sct_slice_num** --> tag (0020,0013), *InstanceNumber*, è la slice interessata dal diametro maggiore del nodulo\n",
        "#     3. Salvataggio della variabile *ImagePatientPosition* della slice ricavata al punto precedente. Utile per la ricostruzione spaziale della slice interessata nel nifti volume.\n",
        "#     4. Trasformazione affine e ottenimento di 3 slice del nifti volume."
      ],
      "metadata": {
        "id": "lxSqHfgRSd50"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # %% Set environment variables at the start of the script\n",
        "    os.environ['LC_ALL'] = 'C.UTF-8'\n",
        "    os.environ['LANG'] = 'C.UTF-8'\n",
        "    os.environ['LANGUAGE'] = 'C.UTF-8'\n",
        "\n",
        "    # --------------------------------------------------------------------------------------------\n",
        "    # %% SEGMENTAZIONE\n",
        "    # --------------------------------------------------------------------------------------------\n",
        "    #dicom_folder = '/Users/mariaprati/Desktop/100334_t1'  # Path to DICOM folder\n",
        "    dicom_folder = '/content/100334_t1'\n",
        "    output_folder = '/content/risultati'  # Path to output results\n",
        "\n",
        "    # Extract the last part of the dicom_folder path (the folder name)\n",
        "    folder_name = os.path.basename(os.path.normpath(dicom_folder))\n",
        "\n",
        "    # Create a new output folder path inside Segmentazione2\n",
        "    output_folder = os.path.join(output_folder, folder_name)\n",
        "\n",
        "    # Ensure the new output folder exists\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    dicom_folder_to_nifti(dicom_folder, output_folder)\n",
        "\n",
        "    # Define paths for the segmentation\n",
        "    #input_image_path = os.path.join(output_folder, f\"{folder_name}_nifti_volume.nii\")\n",
        "    input_image_path = os.path.join(output_folder, f\"{folder_name}_nifti.nii.gz\")\n",
        "\n",
        "    output_dir = os.path.join(output_folder, 'Lung_segmentations')\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Define the lung lobe names\n",
        "    lobe_names = [\n",
        "        'lung_upper_lobe_left',\n",
        "        'lung_lower_lobe_left',\n",
        "        'lung_upper_lobe_right',\n",
        "        'lung_middle_lobe_right',\n",
        "        'lung_lower_lobe_right'\n",
        "    ]\n",
        "    labels = {\n",
        "        'lung_upper_lobe_left': 1,\n",
        "        'lung_lower_lobe_left': 2,\n",
        "        'lung_upper_lobe_right': 3,\n",
        "        'lung_middle_lobe_right': 4,\n",
        "        'lung_lower_lobe_right': 5\n",
        "    }\n",
        "\n",
        "    # Segment the lung lobes using TotalSegmentator\n",
        "    totalsegmentator(\n",
        "        input=input_image_path,\n",
        "        output=output_dir,\n",
        "        #fast=True,\n",
        "        device=\"cpu\",\n",
        "        task=\"total\",\n",
        "        roi_subset=lobe_names\n",
        "    )\n",
        "\n",
        "    # Load the original CT image\n",
        "    ct_img = nib.load(input_image_path)\n",
        "    ct_data = ct_img.get_fdata()\n",
        "\n",
        "    # Output directory for masked images\n",
        "    masked_output_dir = os.path.join(output_dir, 'Lung_segmented_masks')\n",
        "    os.makedirs(masked_output_dir, exist_ok=True)\n",
        "\n",
        "    # Create and save masked images for each region\n",
        "    for region, label in labels.items():\n",
        "        seg_path = os.path.join(output_dir, f'{region}.nii.gz')\n",
        "        if os.path.exists(seg_path):\n",
        "            # Load the specific segmentation file for the current region\n",
        "            seg_img = nib.load(seg_path)\n",
        "            seg_data = seg_img.get_fdata()\n",
        "\n",
        "            # Create a mask for the current region\n",
        "            mask = seg_data == 1  # Assuming the segmentation file has binary mask (1 for region, 0 for background)\n",
        "\n",
        "            # Apply the mask to the original CT data, setting background to -1000\n",
        "            masked_ct_data = np.where(mask, ct_data, -1000)\n",
        "\n",
        "            # Create a new NIfTI image for the masked data\n",
        "            masked_ct_img = nib.Nifti1Image(masked_ct_data, ct_img.affine, ct_img.header)\n",
        "\n",
        "            # Save the masked image\n",
        "            #output_path = os.path.join(masked_output_dir, f'{region}_{folder_name}.nii.gz')\n",
        "            output_path = os.path.join(masked_output_dir, f'{region}.nii.gz')\n",
        "\n",
        "            nib.save(masked_ct_img, output_path)\n",
        "        else:\n",
        "            print(f\"Segmentation file for {region}_{folder_name} not found at {seg_path}\")\n",
        "\n",
        "    print(\"Masked NIfTI files have been saved.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # --------------------------------------------------------------------------------------------\n",
        "    # %% SUBVOLUME\n",
        "    # --------------------------------------------------------------------------------------------\n",
        "    csv_file = \"/content/output.csv\"  # Path to your CSV file\n",
        "    #csv_file = \"/Users/mariaprati/Desktop/filter_51_total.csv\"  # Path to your CSV file\n",
        "    #csv_file = \"/Users/mariaprati/Desktop/filter_51_total_unique.csv\"  # Path to your CSV file\n",
        "\n",
        "    pid = 100334\n",
        "    study_yr = 1\n",
        "\n",
        "    # Load the CSV into a DataFrame\n",
        "    df = pd.read_csv(csv_file)\n",
        "    # Remove duplicates based on pid, study_yr, sct_epi_loc, and sct_slice_num\n",
        "    #df = df.drop_duplicates(subset=['pid', 'study_yr', 'sct_epi_loc', 'sct_slice_num']) #ho commentato qui\n",
        "\n",
        "    # Filter rows for the specified pid and study_yr\n",
        "    rows = df[(df['pid'] == pid) & (df['study_yr'] == study_yr)]\n",
        "\n",
        "    if rows.empty:\n",
        "        raise ValueError(f\"No entries found for pid={pid} and study_yr={study_yr}\")\n",
        "\n",
        "    print(f\"Found {len(rows)} rows for pid={pid} and study_yr={study_yr}\")\n",
        "\n",
        "    # Process each row individually\n",
        "    for index, row in rows.iterrows():\n",
        "        sct_epi_loc = int(row['sct_epi_loc'])\n",
        "        sct_slice_number = int(row['sct_slice_num'])\n",
        "\n",
        "        # Load the lung lobe NIfTI file for the current row\n",
        "        nifti_file, region = load_lung_lobe_nifti(masked_output_dir, folder_name, sct_epi_loc)\n",
        "\n",
        "        print(f\"Loaded NIfTI file: {nifti_file}\")\n",
        "        print(f\"Corresponding region: {region}\")\n",
        "\n",
        "        header = nifti_file.header\n",
        "        affine = nifti_file.affine\n",
        "        data = nifti_file.get_fdata()\n",
        "        pixdim = header[\"pixdim\"]\n",
        "\n",
        "        # Find the slice ImagePatientPosition\n",
        "        result = find_and_save_slices(dicom_folder, sct_slice_number)\n",
        "\n",
        "        if result:\n",
        "            x, y, z = result\n",
        "            print(f\"Target slice ImagePatientPosition: x={x}, y={y}, z={z}\")\n",
        "        else:\n",
        "            print(\"No slice found.\")\n",
        "            continue\n",
        "\n",
        "        # Convert world coordinates to voxel indices\n",
        "        i, j, k = world_to_voxel_coordinates(header, x, y, z)\n",
        "\n",
        "        # Define the window size around the slice\n",
        "        window_size = 1  # ±1 slices\n",
        "        k_min = max(0, k - window_size)\n",
        "        k_max = min(data.shape[2], k + window_size + 1)\n",
        "\n",
        "        # Extract the sub-volume\n",
        "        sub_volume = data[:, :, k]\n",
        "\n",
        "        # Adjust the affine matrix for the sub-volume\n",
        "        new_affine = affine.copy()\n",
        "        new_affine[:3, 3] += k * pixdim[3]\n",
        "\n",
        "        # Create a new NIfTI object for the sub-volume\n",
        "        new_nifti = nib.Nifti1Image(sub_volume, affine=new_affine, header=header)\n",
        "\n",
        "        # Save the sub-volume with a unique name\n",
        "        output_path = os.path.join(\n",
        "            masked_output_dir,\n",
        "            f\"lung_subvolume_pid{pid}_study{study_yr}_row{index}_{region}.nii.gz\"\n",
        "        )\n",
        "        nib.save(new_nifti, output_path)\n",
        "        print(f\"Saved sub-volume for row {index} at: {output_path}\")\n",
        "\n",
        "    print(\"Processing complete.\")\n",
        "        ## aggiungo qui\n",
        "\n",
        "\n",
        "\n",
        "        # --------------------------------------------------------------------------------------------\n",
        "    # %% CLEANUP\n",
        "    # --------------------------------------------------------------------------------------------\n",
        "    # List all files in the output directory\n",
        "    # all_files = os.listdir(masked_output_dir)\n",
        "\n",
        "    # # Define the subvolume files to keep\n",
        "    # files_to_keep = []\n",
        "    # for index, row in rows.iterrows():\n",
        "    #     sct_epi_loc = int(row['sct_epi_loc'])\n",
        "    #     nifti_file, region = load_lung_lobe_nifti(masked_output_dir, folder_name, sct_epi_loc)\n",
        "    #     files_to_keep.append(f\"lung_subvolume_pid{pid}_study{study_yr}_row{index}_{region}.nii.gz\")\n",
        "\n",
        "    # # Delete all other .nii.gz files\n",
        "    # for file_name in all_files:\n",
        "    #     if file_name.endswith('.nii.gz') and file_name not in files_to_keep:\n",
        "    #         file_path = os.path.join(masked_output_dir, file_name)\n",
        "    #         os.remove(file_path)\n",
        "    #         print(f\"Deleted file: {file_path}\")\n",
        "\n",
        "    # print(\"Cleanup complete.\")\n",
        "\n",
        "    # # Delete the .nii.gz files in the 'Lung_segmentations' folder\n",
        "    # segmentation_files = os.listdir(output_dir)\n",
        "    # for file_name in segmentation_files:\n",
        "    #     if file_name.endswith('.nii.gz'):\n",
        "    #         file_path = os.path.join(output_dir, file_name)\n",
        "    #         os.remove(file_path)\n",
        "    #         print(f\"Deleted segmentation file: {file_path}\")\n",
        "\n",
        "    # print(\"Segmentation cleanup complete.\")"
      ],
      "metadata": {
        "id": "wg9uakDySgRp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8e4035d385f94b5e9f4dd8cec28dc443",
            "bf2ad61b23f843ad84078f1515e91c77",
            "b57cdc6b3ff84578b0118b194a9437f2",
            "f65e300c992f4d7b8cdbf7a8bdf6ba31",
            "55e0fefcb9814301a405680308081381",
            "3752f39d2c284e16b1ec51f04004ae86",
            "6e947b2fe8ea46c8b47d5cecec817a5d",
            "7337612d4ac141d5b5b9b16bb501e899",
            "51b1d79488c446c28de08315d5547e46",
            "afa4d3121913481b8688523b81277676",
            "bb9e9f514c4b4fe6993e9fcb3ca47f02"
          ]
        },
        "id": "rcovdguXSnWg",
        "outputId": "cc730c41-d35a-4760-9ec0-4ed39bbdeab7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DICOM to NIfTI conversion successful!\n",
            "Output: Chris Rorden's dcm2niiX version v1.0.20220505  GCC11.4.0 x86-64 (64-bit Linux)\n",
            "Found 109 DICOM file(s)\n",
            "Convert 109 DICOM as /content/risultati/100334_t1/100334_t1_nifti (512x512x109x1)\n",
            "Conversion required 4.132330 seconds (4.108681 for core code).\n",
            "\n",
            "\n",
            "If you use this tool please cite: https://pubs.rsna.org/doi/10.1148/ryai.230024\n",
            "\n",
            "Generating rough segmentation for cropping...\n",
            "Resampling...\n",
            "  Resampled in 1.41s\n",
            "Predicting...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n",
            "100%|██████████| 1/1 [00:01<00:00,  2.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Predicted in 13.97s\n",
            "Resampling...\n",
            "  cropping from (512, 512, 109) to (452, 324, 109)\n",
            "Resampling...\n",
            "  Resampled in 2.55s\n",
            "Predicting part 1 of 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n",
            "100%|██████████| 8/8 [02:05<00:00, 15.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Predicted in 142.98s\n",
            "Resampling...\n",
            "Saving segmentations...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e4035d385f94b5e9f4dd8cec28dc443"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved in 5.75s\n",
            "Masked NIfTI files have been saved.\n",
            "Found 2 rows for pid=100334 and study_yr=1\n",
            "Loaded Left Upper Lobe\n",
            "Loaded NIfTI file: \n",
            "<class 'nibabel.nifti1.Nifti1Image'>\n",
            "data shape (512, 512, 109)\n",
            "affine:\n",
            "[[  -0.66406202   -0.            0.          166.3999939 ]\n",
            " [   0.            0.66406202    0.         -190.63569641]\n",
            " [   0.            0.            2.5        -288.07998657]\n",
            " [   0.            0.            0.            1.        ]]\n",
            "metadata:\n",
            "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
            "sizeof_hdr      : 348\n",
            "data_type       : b''\n",
            "db_name         : b''\n",
            "extents         : 0\n",
            "session_error   : 0\n",
            "regular         : b'r'\n",
            "dim_info        : 0\n",
            "dim             : [  3 512 512 109   1   1   1   1]\n",
            "intent_p1       : 0.0\n",
            "intent_p2       : 0.0\n",
            "intent_p3       : 0.0\n",
            "intent_code     : none\n",
            "datatype        : int16\n",
            "bitpix          : 16\n",
            "slice_start     : 0\n",
            "pixdim          : [-1.        0.664062  0.664062  2.5       0.        0.        0.\n",
            "  0.      ]\n",
            "vox_offset      : 0.0\n",
            "scl_slope       : nan\n",
            "scl_inter       : nan\n",
            "slice_end       : 0\n",
            "slice_code      : unknown\n",
            "xyzt_units      : 10\n",
            "cal_max         : 0.0\n",
            "cal_min         : 0.0\n",
            "slice_duration  : 0.0\n",
            "toffset         : 0.0\n",
            "glmax           : 0\n",
            "glmin           : 0\n",
            "descrip         : b'Time=0.000'\n",
            "aux_file        : b''\n",
            "qform_code      : scanner\n",
            "sform_code      : scanner\n",
            "quatern_b       : 0.0\n",
            "quatern_c       : 1.0\n",
            "quatern_d       : 0.0\n",
            "qoffset_x       : 166.4\n",
            "qoffset_y       : -190.6357\n",
            "qoffset_z       : -288.08\n",
            "srow_x          : [ -0.664062  -0.         0.       166.4     ]\n",
            "srow_y          : [   0.          0.664062    0.       -190.6357  ]\n",
            "srow_z          : [   0.      0.      2.5  -288.08]\n",
            "intent_name     : b''\n",
            "magic           : b'n+1'\n",
            "\n",
            "Corresponding region: lung_upper_lobe_left\n",
            "Slice with InstanceNumber 36 found at index 35.\n",
            "ImagePatientPosition: x=-166.399994, y=-148.699997, z=-105.580002\n",
            "Target slice ImagePatientPosition: x=-166.399994, y=-148.699997, z=-105.580002\n",
            "Saved sub-volume for row 151 at: /content/risultati/100334_t1/Lung_segmentations/Lung_segmented_masks/lung_subvolume_pid100334_study1_row151_lung_upper_lobe_left.nii.gz\n",
            "Loaded Left Lower Lobe (including Lingula)\n",
            "Loaded NIfTI file: \n",
            "<class 'nibabel.nifti1.Nifti1Image'>\n",
            "data shape (512, 512, 109)\n",
            "affine:\n",
            "[[  -0.66406202   -0.            0.          166.3999939 ]\n",
            " [   0.            0.66406202    0.         -190.63569641]\n",
            " [   0.            0.            2.5        -288.07998657]\n",
            " [   0.            0.            0.            1.        ]]\n",
            "metadata:\n",
            "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
            "sizeof_hdr      : 348\n",
            "data_type       : b''\n",
            "db_name         : b''\n",
            "extents         : 0\n",
            "session_error   : 0\n",
            "regular         : b'r'\n",
            "dim_info        : 0\n",
            "dim             : [  3 512 512 109   1   1   1   1]\n",
            "intent_p1       : 0.0\n",
            "intent_p2       : 0.0\n",
            "intent_p3       : 0.0\n",
            "intent_code     : none\n",
            "datatype        : int16\n",
            "bitpix          : 16\n",
            "slice_start     : 0\n",
            "pixdim          : [-1.        0.664062  0.664062  2.5       0.        0.        0.\n",
            "  0.      ]\n",
            "vox_offset      : 0.0\n",
            "scl_slope       : nan\n",
            "scl_inter       : nan\n",
            "slice_end       : 0\n",
            "slice_code      : unknown\n",
            "xyzt_units      : 10\n",
            "cal_max         : 0.0\n",
            "cal_min         : 0.0\n",
            "slice_duration  : 0.0\n",
            "toffset         : 0.0\n",
            "glmax           : 0\n",
            "glmin           : 0\n",
            "descrip         : b'Time=0.000'\n",
            "aux_file        : b''\n",
            "qform_code      : scanner\n",
            "sform_code      : scanner\n",
            "quatern_b       : 0.0\n",
            "quatern_c       : 1.0\n",
            "quatern_d       : 0.0\n",
            "qoffset_x       : 166.4\n",
            "qoffset_y       : -190.6357\n",
            "qoffset_z       : -288.08\n",
            "srow_x          : [ -0.664062  -0.         0.       166.4     ]\n",
            "srow_y          : [   0.          0.664062    0.       -190.6357  ]\n",
            "srow_z          : [   0.      0.      2.5  -288.08]\n",
            "intent_name     : b''\n",
            "magic           : b'n+1'\n",
            "\n",
            "Corresponding region: lung_lower_lobe_left\n",
            "Slice with InstanceNumber 84 found at index 83.\n",
            "ImagePatientPosition: x=-166.399994, y=-148.699997, z=-225.580002\n",
            "Target slice ImagePatientPosition: x=-166.399994, y=-148.699997, z=-225.580002\n",
            "Saved sub-volume for row 152 at: /content/risultati/100334_t1/Lung_segmentations/Lung_segmented_masks/lung_subvolume_pid100334_study1_row152_lung_lower_lobe_left.nii.gz\n",
            "Processing complete.\n"
          ]
        }
      ]
    }
  ]
}
